{
  "video_id": "eDY9FUT5ces",
  "summary": "Un chercheur présente son travail sur l'apprentissage automatique et le raisonnement humain. Il souligne que les modèles de langage artificiels (LLM) sont encore limités pour résoudre des problèmes de raison. Un exemple claque les capacités des LLM : tourner un engrenage dans un cercle. Le chercheur explique que ce type de problème nécessite une image mentale et une capacité à raisonner de manière intuitive, qualités humaines qui sont difficiles pour les machines à comprendre. Les LLM peuvent résoudre ces problèmes si ils sont entraînés avec la bonne réponse, mais pas autrement.",
  "timestamp": 1747909001.899878,
  "transcript": "[Musique] ok bonsoir bonsoir madames messieurs l'intérêt pour invité de ce soir témoignant bien de l'importance du moment que nous vivons allô ça va ok depuis presque 2 ans les modèles de langues ont fait une entrée spectaculaire dans nos vie bienin travaill discrètement pendant des années ils occupent désormais une place visible et irréversible à nos côtés les systèmes d'intelligence artificielle perçoivent les mondes à travers l'écrit comme l'auteur du livre de Marco Polo à 14e siècle leur connaissance de la réalité est indirecte et parfois imprécise notre intervenant ce soir nous éclairera sur Pourquoi et comment la prochaine génération de la système d'intelligence artificielle devra comprendre le monde en observant directement et en interagissant avec lui plutôt que de se limiter à ce qui a été écrit par les auteurs y le est silver professor à l'université de New York et vice presidentief scienem lorsquil était étudiant y les on été profondément inspiré par les travaux de psychologue suisse Jean piager en particulierre ces théories sur le constructivisme et le développement cognitif il a aussi été marqué par les films 2001 l'odysaye d'espace sorti en 1968 qu'elle a poussé à réfléchir aux possibilités offertes parinttelligence artificielle à la interaction entre les machine et la conscience humaine dans les années 19490 il a développé pas des modèles des réseaux de neuron artificiels qui ont en cœur de la Révolution d'apprentissage profonde et ont constitué la Fondation des modèles à grande échelle tel que jpet entre 1990 et 2010 il a été l'un des RAR à défendre cette technologie alors que la communauté scientifique leerait son immense contribution a été reconnue par des nombreux prix notamment les prix Touring les plus hautes distinctions informatique qu'elle reçu en 2018 avec Joffrey Hinton et Josu reste un chercheur passionnante et visionnaire et c'est un véritable honneur de accueillir ce [Applaudissements] soir merci Slavin alors je vais le titre est en anglais mais je vais parler en français en tout cas c'est ce qu'on m'a demandé alors comment les machines pourrai-ell atteindre l'intelligence de nveau humain comme l'a mentionné Slava et comme je l'ai mentionné ce matin au moment de la cérémonie de de remise des diplôme honorisaa j'ai été inspiré à travailler sur l'apprentissage automatique par ce livre la traduction française de ce livre en fait il existe en anglais aussi qui était le le contte-rendu d'un débat ou la transcription d'un débat entre Jean-Pierre J et no Chomski entre des équipes de de chercheurs qui étaient venus argumenter d'un côté sur le fait que le le langage est inné et d'autres de l'autre côté sur le fait que le langage est appris et dans ce débat participait un certain SIM Papert qui était un mathématicien qui à l'époque était professeur à mit mais qui avait passé du temps dans le laboratoire de jean-pierget ici et euh qui avait travaillé sur des les modèle d'apprentissage relativement simple de l'époque le perceptron en particulier euh et il chantait les louange du percepon dis an euh au au aux scientifiques plutôt du côté de Chomski même cette machine très simple était capable de d'apprendre des concepts bizarrement compliqués ce que j'ai appris plus tard c'est que en creusant la littérature ce que j'ai je suis devenu passionné de cette histoire de machine capable d'apprentissage c'est que le même SIM Papert avait écrit le livre co co-écrit le livre avec Marvin Minsky publié en 1969 qui avait en fait tuer le domaine de recherche en question c'est-à-dire que la recherche sur le réseau neurone était devenue tabou à la fin des années 60 à cause de ce livre donc le voilà 10 ans plus tard chantant les louanges du percettron alors qu'il en avait contribué à à la à la perte alors c'est un petit peu paradoxal mais ça m'a pas empêché de creuser la littérature de réaliser qu'elle était un peu ancienne qu'il y avait quelques auteurs japonais qui avaient continuer à travailler là-dedans et puis j'ai découvert au début de de mes études de 3e cycle que en fait il y avait une population une petite population de gens qui s intéressé aux problèm principalement aux États-Unis un petit peu en Angleterre et en Allemagne et un petit peu au Japon qui travaillaient sur les sur les réseaux neuron en particulier deux personnages John hoffield et Jeff hintton qui ont reçu le prix Nobel il y a quelques jours en physique euh les modèles pour lesquels ils ont reçu pr Nobel ne sont plus utilisés du tout il ne marchent pas particulièrement bien mais par contre leurs articles ont eu un impact assez énorme sur le domaine c'est qu'ils ont justement levé le tabou et ils ont euh contribué à à rendre euh le domaine de des réseaux neurones euh acceptable ou respectable de nouveau et donc ont contribuait à créer une nouvelle vague d'intérêt pour ces pour ces modèles euh qui a duré un peu plus d'une dizaine d'années entre le début des années 80 et le milieu des années 90 et puis on a assisté à une autre euh un autre hiver des réseaux neurone si vous voulez jusque jusqu'au début des années 2010 ou la fin des années 2000 voilà assez d'histoire euh on a besoin d'intelligence artificielle aussi intelligente que les humains pour certaines personnes ça fait peur mais pour d'autres c'est plutôt un espoir porte porteur d'espoir et la raison pour laquelle on en a besoin c'est que il y a un futur probablement pas très distant je pense que beaucoup de gens dans la salle ici le le verront qui dans lequel tout un chacun interagira avec des des systèmes d'intelligence artificielle des assistants qui sonont avec nous euh toute la journée qui nous aideront dans nos tâches de tous les jours qui nous aideront à résoudre des problèmes et cetera ces systèmes seront peut-être plus intelligents que les humains mais seront à notre service c'est-à-dire que on leur donnera des on le posera des questions on leur donnera des problèmees à résoudre il les résoudront pour nous mais les buts les les les tâches qu'ils accompliront seront déterminé par les humains ce sera un petit peu comme disons un un un directeur de laboratoire académique ou un chef d'entreprise ou peut-être un leader politique accompagné d'un d'un d'un staff de gens qui le qui les conseillent à tout moment et qui sont très probablement plus intelligents qu'eux enfin peut-être pas c'est peut-être pas le cas pour les membres de du monde académique mais c'est certainement vrai pour les politiciens et il ne faut pas se sentir menacé par l'idée qu'on va être accompagné de d'entité plus intelligente que nous en fait ça va démultiplier notre intelligence l'amplifier on devrait de même qu'on devrait pas se sentir menacé de travailler avec des gens plus intelligents que nous je sais pas si c'est votre cas mais en tout cas pour moi je suis très habitué à travailler avec des gens qui sont plus intelligents que moi en fait je ne fais j'espère ne n'embaucher que des gens qui sont plus intelligents que moi donc voilà et il faut que ces systèmes avec lesquels on interagit euh en fait soit facile à à piloter qui soit très facile d'interagir avec eux et pour ça il leur faut une intelligence proche deintelligence humaine peut-être supérieure en terme de de puissance mais en terme de qualitatif qui soit relativement similaire pour simplifier simplement notre communication avec eux donc ça nécessite des machines qui qui qui qui qui comprennent le le monde physique de même que nous on comprend le monde physique et tout animal comprè le monde physique des systèmes qui ont une mémoire persistante des systèmes qui puissent planifier des actions complexes de manière à remplir un objectif des systèmes qui puissent raisonner et puis des systèmes qui soient contrôlables et sécurisé c'est-à-dire qu' ne vont pas par exemple si on leur demande d'aller nous chercher un café et que il y a une autre personne qui bloque le chemin pour aller à la machine à café ne vont pas piétiner cette pauvre personne ou la trucidée simplement pour accéder à la machine à café alors ça bon ça fait partie des scénarios de la science-fiction et cetera ce problème en fait d'alignement des des objectifs avec les valeurs humaines n'est pas un problème aussi compliqué et insoluble que certains ont bien voulu le dire alors qu'est-ce que ça veut dire ça est-ce que ça veut dire prendre les systèmes actuels tels que les les les LLM l'argentement'ance ou ou des des architectures similaires et est-ce qu'on va arriver à l'intelligence de niveau humain simplement en entraînant ces systèmes avec plus de données et ou simplement en les entraînant avec plus de puissance de calcul plus de raffinement et cetera et ma réponse à cette question est absolument pas absolument pas non les LLM sont très utiles très puissants plein il y a plein d'applications à développer avec eux mais ils ne mèneront pas par eux-mêmes à des systèmes de niveau d'intelligence humaine alors je je n'utilise pas l'acronyme consacré un petit peu pour ça qui est agi en anglais artificial general intelligence euh intelligence artificielle générale j'ai horreur de ce terme parce que euh si on l'utilise pour désigner des systèmes qui ont l'intelligence humaine on fait un énorme contresens à cause du fait que l'intelligence humaine n'est pas du tout général l'intelligence humaine est très spécialisée on a un petit peu de mal à à s'imaginer que l'intelligence est spécialisé mais en fait c'est simplement parce qu'on a du mal à imaginer des problèmes qu'on ne peut pas résoudre donc euh Hi est un très mauvais nom donc je préfère soit HLI human level artifici intelligence en anglais ou tel qu'on l'appelle en interne chez chez MTA on a un très joli nom pour vous pour pour ça c'est ami ami en français etemi en anglais ça veut dire advance machine intelligence voilà c'est beaucoup plus raisonnable alors le premier problème de comment construire des machines intelligentes c'est le problème de l'inférence l'inférence qu'est-ce que ça veut dire c'est simplement le processus par lequel le système calcule sa sortie si on a un réseau de neurone ou un système de Deep learning classique la manière dont le système calcule sa sortie c'est que on lui donne une entrée on propage ses entrées à l'intérieur du du système et le système produit une sortie c'estàdire qu'il y a un nombre d'étapes de calcul pour calculer la sortie qui est fixe les LLM ont cette propriété que on leur donne un prompte une entrée et pour produire un token c'est-à-dire un espèce de mot la quantité de calcul euh qui va servir à calculer un mot le mot suivant dans la dans la séquence est fixe ce qui fait que ces systèmes là ne peuvent pas vraiment réfléchir réfléchir ça veut dire passer plus de temps sur les problèmes compliqués que sur les problèmes simples la seule manière qu'on qu'on peut employer pour faire en sorte que les LLM passe plus de temps à réfléchir c'est leur faire produire plus de token c'est-à-dire des des mot qui ne servent à rien alors il y a un autre modèle qui s'appelle l'inférence par par optimisation qui consiste à à faire en sorte que le le le système entre son entrée et son et sa sortie calcule une espèce de quantité qui mesure la compatibilité entre l'entrée et la sortie donc si on a une entrée et une sortie qu'on propose au système qui sont compatibles le système calcule un nombre euh qu'on peut appeler une une énergie et ce nombre sera petit disons zéro si euh on donne une image d'un éléphant et le système dit la on lui propose la sortie éléphant il nous dit zéro parce que éléphant est compatible avec l'image si on donne une image d'un éléphant et on donne en en en sortie proposée euh l'étiquette chat le système donne une énergie plus haute 10 donc la manière dont un système de ce type là calcule sa sortie c'est on lui donne une entrée et ensuite il cherche parmi euh toutes les sorties possibles cell ou une qui minimise ce nombre cette énergie c'est compatibilité entre le l'entrée et la sortie alors il peut faire cette recherche de manière exhaustique faire c'est un espace avec une méthode de DESC de gradient et c'est ceon appelleinférence c'est une méthode d'inférence qui est intrinsquement plus puissante que simplement propager un signal à travers des couchesauur d'un point de vue conceptuel théorique on peut réduire pratiquement tout problème un problème d'optimisationd d'inférence type que je décris mais on peut pas toujours réduire le calcul d'uneune sortie la solution d'un problème comme le résultat d'un nombre fixe d'étapes de de calcul qui est le cas de la propagation avant dans un dans un réseau neur donc c'est intrinsèquement plus plus puissant et ça c'est un modèle complètement différent de ce qu'on emploie à l'heure actuelle dans les dans les LLM et dans la plupart des systèmes d'IA ce genre de de technique d'inférence a été utilisé dans des systèmes d'IA capablebles d'apprentissage en particulier système capable de de jouer à des jeux tels que tels que les échecs et cetera où on im imagine un certain nombre de scénarios du futur de ce que va jouer l'adversaire et puis parmi t tous les scénarios imaginés on choisit celui qui est le plus propice à à conduire à une victoire voilà donc c'est cette idée de d'inférence par optimisation conduit à une architecture que j'appelle objective driven ai donc Ia piloté par les objectifs qui qui qui qui permettrait en fait à des systèmes d'IA de d'être de résoudre des problèmes que les systèmes d'IA classiques de à base de de logique des années 80 90 était capable de résoudre c'est-à-dire une recherche de solution dans un espace de de solution possible une idée qui remonte aux années 50 mais qui a disparu un petit peu dans les les modèles d'IA actuels donc cette ce calcul de sortie par optimisation je pense est très important et c'est un petit peu ce qu'on on imagine peut-être une une concrétisation de ce que les les psychologues appellent système 2 donc dans les les action humaine ou animale système 1 correspond aux actions qu'on qu'on accomplit de manière subconsciente sans vraiment il penser qui sont un peu automatiques on est tellement habitué à les résoudre que on n pas besoin de réfléchir à quelle action prendre et puis système 2 c'est ce qui ce qui requiert notre attention notre science notre modèle du monde et qui nous permet d'imaginer en fait quel va être le résultat d'une séquence d'action et donc qui nous permet de planifier une séquence d'action al pour capturer les dépendances entre des entrées et des sorties à partir de ces ces fonctions d'énergie il faut utiliser enfin une bonne manière de se représenter ça c'est ce qu'on appelle les les modèles à base d'énergie energy bas en anglais qui capture les dépendances entre des variables x et y disons dans le le diagram ici qui sont scalaires mais qui pourra être n'importe quoi discrète continue aux dimensions et cetera donc la la fonction d'énergie doit prendre des énergies basses dans les paires X Y qui dont on sait qu'elles sont compatibles donc on peut supposer qu'elles sont présentes dans un ensemble d'apprentissage qu'on va utiliser pour entraîner la machine donc le l'apprentissage d'une machine de ce type là consiste à changer les paramètres de cette fonction d'énergie qui va être un gros réseau neurone avec une seule sortie scalaire de manière à ce que cette sortie scalaire prenne une valeur faible disons zéro ou aussi faible que possible pour des paires qui sont présenté durant l'apprentissage des paires X Y qui sont dans l'ensemble d'apprentissage qui sont symbolisé par les les points noirs ici les disques noirs et puis une fonction d'énergie qui va qui va prendre des valeurs plus élevées pour les points qu'on lui montre pas et c'est là que ça devient compliqué pour entraîner un système à base d'énergie c'est comment faire en sorte que la fonction énergie prend des valeurs supérieur pour des exemples qu'on ne lui montre pas c'est particulièrement compliqué si l'espace en question est de haute dimension alors je vais faire une petite parenthèse sur les les modèles génératifs et les LLM avant de vous expliquer comment on entraînent ces modèles à base d'énergie donc les LM sont des modèles ce qu'on appelle autorégressifs et donc ce sont LLM autorégressifs qui sont entraînés à prédire un mot à partir des mots qui qui sont à gauche de ce mot donc c'est très facile à entraîner on prend un morceau de texte et puis on entraîne le système à prèsd dire tous les mots qui sont entrée mais le système ne peut ne peut pas utiliser l'entrée pour ne peut pas simplement copier son entrée sur sa sortie parce qu'il ne peut utiliser que les mots qui sont à gauche du mot qu'il doit prédire et donc en fait il est entraîné implicitement à prédire le mot qui suit une séquence de mot alors une fois qu'il a été entraîné à à prédire le mot qui suit on peut lui faire bien sûr on pe lui don un début de texte qui peut être une question et puis lui demander de prédire le mot suivant ensuite on injecte ce mot dans l'entrée on lui demande de prédire le mot le deuxème mot on injectce ça dans l'entrée 3ème mot et cetera ça c'est prédiction autorégressive c'est pas un nouveau concept ça date de matthusalem mais il n'y a pas de comme je disais précédemment il y a pas de réflexion il y a pas de raisonnement il y a pas de planification il y il y a pas de modèle mental du monde c'est purement prédire le prochain token ou le prochain mot à partir des statistiques des données d'entraînement alors c'est très utile c'est bizarrement quand même assez blufffant et intelligent si on entraîne un très gros réseau de neurone à faire ça en fait il est capable de mémoriser énormément de de situations et donc et donc presque quelque fois de résoudre des problèmes et cetera mais aussi de faire des grosses erreurs et ils ne sont pas capables de raisonnement alors beaucoup de gens dans le domaine travaille sur le raisonnement c'est le cas de beaucoup de gens à ma à Google et à Open et puis à d'autres d'autres endroits et puis dans des laboratoires universitaires et en fait il y a toute une série d'articles de depuis plusieurs années en particulier par le professeur souaraoati qui est arizona state et qui qui vient un un petit peu de de l plus traditionnel et qui qui qui qui montre tout un tas d'expériences montrant que les les LLM en fait ne sont pas vraiment capables de planification donc il y a un certain nombre de problèmes de planification qui sont un peu classiques on y a alors ça fait mais pas encore et pu les gens qui viennent des SCI cognitiv et disent vraiment les ne sont pas cap de faire le genre de généralisation et planification don sont cap les cerau non se des humains mais aussi de beaucoup d'animau alorsut construire modè de typ qui fait son inférence par optimisation il faut quandme structurer Peuil ID de structuration construit autour module que j'appelle modèle du monde en anglais et l'architecture est comme comme celle qui est indiquée ici on fait une observation de l'environnement c'est pas le monde entier hein c'est ce qu'on peut saisir avec des capteurs des caméras et cetera cette entrée va dans un système de perception qui estlabore une représentation abstraite de de l'environnement perceptuel qui est ici indiqué par le initial World state representation donc la représentation de l'état initial du monde alors évidemment euh aujourd'hui là je suis en train de regarder cette cette cette salle j'ai une idée de de l'état du monde dans cette salle et bien sûr cette perception ne change pas mon idée de l'état du reste du monde donc je dois combiner mon idée de l'état du monde ici avec le contenu d'une mémoire qui est dans dans l'hippocampe dans dans cerveau humain dans CER des mammifères et qui contient une quantité de de connaissance et de savoir sur sur le monde et qui ne change pas avec la la perception courante tout cela va dans un un modèle du monde et le rôle du modèle du monde est d'imaginer quel va être l'état résultant donc de prédire quel va être l'état du monde après que l'agent a effectué une séquence d'action donc l'agent imagine une séquence d'action symbolisé en jaune ici cette séquence d'action est donnée au modèle du monde et le modèle du monde à partir de la séquence d'action imaginée et de l'état initial du monde produit une prédiction ou peut-être plusieurs prédictions sur l'état futur du monde résultant de cette séquence d'action ensuite euh cette cet état prédit est est donné à une série de de fonction de coût de fonction d'objectif dont la la dont la sortie n'est pas représentée mais c'est un scalaire tout simplement euh le premier est euh un objectif lié à la tâche donc il va nous donner un nombre faible disons zéro si une tâche particulière a été accomplie et puis un un nombre plus grand si la tâche n'a pas été accomplie et puis un autre ensemble d'objectifs qui sont des des des gardes fous donc des des des fonctionons de cou qui garantissent que la séquence d'état ou la séquence d'action que produit le système ne met pas en danger les utilisateurs qui sont autour par exemple donc on peut poser que une sorte de de sécurisation du système en en entraînant ou en construisant ses objectifs gardefou alors la manière dont le système fonctionne c'est que étant donné une perception et puis contenue la mémoire et puis une hypothèse sur une séquence d'action le système prédit le le le résultat donne ça au fonction de cût et ensuite par optimisation essaie de de de changer de modifier la séquence d'action imaginé de manière à ce que cette séquence d'action minimise à la fois l'objectif de la tâche et les objectifs gardefou d'accord donc c'est de l'inférence par optimisation mais qui est connecté à une un modèle mental de du monde qui prédit ce qui va ce qui va se passer d'accord alors très souvent les les modèles du monde ne peuvent pas prendre une séence une grande séquence d'action et prédire ce qui va se passer mais on doit peut-être itérer notre modèle du monde sur plusieurs plusieurs fois pour arriver à à prédire ce qui va se passer donc imaginons une séquence de deux actions euh on on donne la première action à notre modèle du monde qui prédit ce qui va se passer dans un futur proche comme conséquence de cette première action et puis ensuite une deuxième action au modèle du monde qui va prédire ce qui va se passer plusieurs fois et cetera donc on prévoit plusieurs coupts en fait quel va être le résultat et puis ensuite par optimisation qui peut être basé sur la rétropréparation de gradient mais on parle pas d'apprentissage encore trouver de quelle manière changer les les actions de manière à minimiser les fonctions de coût alors encore une fois on ne fait pas de je n'ai pas parlé d'apprentissage encore là c'est juste pour l'inférence pour le calcul de la sortie qui peut se faire par par descent de gradient ou par une autre méthode d'optimisation combinatoire ou autre alors malheureusement le monde n'est pas entièrement déterministe ou même si'il est déterministe que disent les physiciens euh il n'est pas entièrement prédictible parce qu'il est pas complètement observable euh et puis dans tous les cas il peut être chaotique donc très difficile à prévoir donc les les le modèle du monde ne peut pas faire une une prévision exacte et donc il va falloir probablement lui donner ce qu'on appelle les variables attente c'est-à-dire des variables dont on ne connaît pas la valeur mais dont on prend la valeur soit euh échantillonné dans une distribution ou euh qu'on qu'on fait circuler dans dans un ensemble pour produire des des des prédictions multiples de de ce qui peut se passer à cause de l'incertitude sur le monde bien sûr il peut se passer tout un tas de choses qu'on peut pas prédire mais toutes les fonctions qui sont représentées dans dans ce diagramme donc toutes les fonctions qui sont arrondies un bout sont des fonctions déterminis qu'on peut calculer c'est un réseau de neur quelque chose comme ça on lu donne une entrée il calcule la sortie aune sortie si on veut lui faire calculer plusieurs sorties il faut une variable attente dont on fait varier la valeur c'est aussi simple que ça alors les les humains et les animaux ne planifient pas une séquence d'action à un niveau c'estàdire que si on planifie par exemple d'aller de Genève à New York et qu'on décide de passer d'arriver à New York demain après-midi ce qui va être mon cas là tout de suite on ne fait pas une planification de Genève à New York en terme de de contrôle musculaire toutes les milliseces en fait le niveau le plus bas des actions pour le cerveau humain c'est le contrôle les muscles mais on peut pas planifier un voyage de Genève à New York millisees par milliseonde en terme de contrôle musculaire on fait la planification hiérarchique c'està-dire que on fait d'abord un scénario très abstraitù on dit pour aller à New York il va falloir que j'aille à l'aéroport et que je prenne un avion pour New York bon donc ça ça nous donne un sous-objectif qui est aller à l'aéroport comment je vais à l'aéroport il faut que j'appelle un taxi qui m'emmène à l'aéroport ou que je prenne des transports en commun disons je prends un taxi alors faut que j'appelle le taxi puis ensuite il faut que j'aille dans la rue comment je vais dans la rue euh il faut que je marche jusqu'à la porte et puis que j'aille dans la rue comment je vais jusqu'à la porte il faut déjà que je sache où elle est et puis euh il faut que je mette un pied devant l'autre comment je mets un pied devant l'autre alors on peut descendre comme ça jusque jusqu'en bas jusqu'au niveau de contrôle musculaire et en fait cette hiérarchie est très profonde jusqu'à un niveau on a plus besoin de planifier parce que les tâches sont tellement simples qu'on a pas besoin d'y réfléchir on peut les accomplir de manière subconsciente mais la planification hiérarchique ce problème de planification hiérarchique est complètement non résolu en Y a si vous êtes un étudiant qui pense à faire un doctorat en Y a essayer de résoudre ce problème c'est complètement vierge ça veut pas dire que les gens y ont pas travailler ça veut dire qu'on sait pas le faire avec des techniques d'apprentissage on sait le faire si on construit les choses à la main la plupart des robots aujourd'hui utilisent la planification hiérarchique mais c'est entièrement fait à la main donc comment apprendre ça comment apprendre le modèle du monde comment apprendre ses fonctions d'objectif et ses et ses et ses gardefous ces trois problèmes sont essentiellement pas résolus mais je vais quand même vous montrer des exemples euh qui montrent qu'on qu'on fait des progrès donc en fait toutes ces idées construit contribuent à une espèce de d'architecture globale d'un système intelligent que j'appelle objective driven ai objective driven architecture et j'ai décrit un petit peu le le plan de tout ça dans un article que j'ai publié il y a 2 ans et demi dont l'adresse est ici donc c'est sur Open review pas sur archive sur Open review parce que vous pouvez faire des commentaires et me dire si j'ai tort euh et euh et et et je serais très content que vous dit disaz ça ça viterit de perdre du temps et puis de peut-être corriger cet article euh et donc c'était avant chat GPT tout ça mais le plan n'a pas changé donc c'est un petit peu mon idée sur où devrait aller la recherche en intelligence artificielle dans les 10 ans qui viennent enfin maintenant plus que les 7 ans et demi parce que ça fait 2 ans et demi voilà donc si ce projet est couroné de succès on aura des architectures peut-être qui peuvent atteindre le niveau d'intelligence humaine dans 7 ans et demi Marc Zuckerberg aime bien m'entendre dire ça mais je peux rien promettre donc c cette architecture en fait donc est composée de ces modules un petit peu les mêmes dont j'ai parlé tout à l'heure alors là ils sont arrangés de manière un petit peu différente c'est un peu plus conceptuel mais un système de perception un modèle du monde dont j'ai parlé tout à l'heure un acteur qui est le le module qui essaie de trouver la la séquence d'action optimale pour satisfaire un nombre d'objectifs et puis les objectifs qui sont les les coûts ici les en rouge la mémoire à court terme et puis un modèle un module un petit peu mystérieux en haut là qui s'appelle le configurateur qui sert en fait à configurer le système pour accomplir une tâche particulière pour satisfaire un but particulier alors je peux pas dire qu'on a construit ce système mais on est en train de construire les modules essentiels en fait qui qui sont nécessaires et à terme on espère avec ce genre d'architecture avoir des systèmes qui sont capables de comprendre le le monde physique sont capables de mémoire persistante sont capables de raisonnement et de de planification et qui sont aussi contrôlables à partir des objectifs et des des gardesfous alors comment comment apprendre des des modèles du monde à partir de de données sensorielles on peut on peut toujours essayer d' utiliser l'apprentissage supervisé c'est-à-dire dire une machine voilà voilà é du monde à l' instant voilà une action que je prends fais fais attention au fait que il faut pas trop tourner à gauche parce que tu es dans une voiture autonome qui conduit juste à côté d'un d'une falaise des montagnes suisses et tu vas te retrouver dans en bas de en bas de la falaise mais bien sûr on peut pas se permettre d'annoter des quantités de données énormes pour dire au système fais ceci fais pas ça et cetera alors ce qu'il faudrait c'est que le système apprennent comment fonctionne le monde par lui-même par observation peut-être à la manière des des jeunes animaux et des des des enfants humains qui dans les premiers mois de la vie ont très peu d'interaction directe avec le monde c'est peuvent pas vraiment influencer le monde externe mais par contre observe et arrive à à prendre une quantité de connaissance sur le sur le monde qui est absolument extraordinaire alors euh malheureusement on on il nous manque des composants vraiment essentiel pour accomplir ce ce but euh on va pas le faire avec du texte il va falloir pouvoir entraîner des systèmes à partir de vidéo et la raison pour laquelle on n pas enfin un des indices qui montre qu'on a pas encore réussi à le faire complètement et que on a des LLM qui peuvent qui peuvent passer des examens au barreau euh aussi bien qu'un avec un avocat j'espère qu'il y a pas beaucoup d'avocats dans la dans la euh ou qui peuvent répondre à tout un tas de questions qui ont l'air compliqué mais en fait qui sont font partie de l'ensemble de l'apprentissage donc il ont certainement une grande mémoire mais on a toujours pas de robot domestique qui puissent débarrasser la table et remplir la vaisselle une tâche qu'un gamin 10 ans peut apprendre en une fois c'est-à-dire sans qu'on lui explique comment où on a toujours pas de malgré ce que raconé l musk on a toujours pas de de voitures qui peuvent se conduire toute seule en avec autant de fiabilité qu'un qu'un humain sans intervention humaine alors il il y en a bien sûr qui existent mais qui trichent c'està-dire qui qui ont une carte complète de l'environnement qui ont des des capteurs qui sont au-delà de l'aquité humaine et cetera chez wo ou Cruise ou d'autres mais des des voitures vraiment autonomes on en a pas encore alors que n'importe quel adolescent est capable d'apprendre à conduire une voiture en une vingtaine d'heures de pratique essentiellement sans sans accident en tout cas certainement sans conduire la voiture pardà une falaise si c'était le cas on aurait pas beaucoup de Suiss et puis bon c'est pas seulement les humains aussi les chats si vous avez vu un chat ou même un une chèvre euh en bas d'une série d'obstacles planifier comment l'animal va sauter pour arriver en haut c'est assez extraordinaire donc c'est un autre exemple de ce qu'on appelle le paradoxe de Mor avec et on peut mettre un petit chiffre là-dessus c'est que les les plus gros LLM aujourd'hui sont sont entraînés typiquement avec 20000 milliards de token un token c'est comme un mot c'est un sousmo si vous voulez chaque token est environ 3 oct donc ça fait un volume d'environ 6 10 à la puissance 13 un 6 avec 130 derrière disons un 1 avec 14 0 derrière pour faire bonne bonne figure ça prendrait quelques centaines de milliers d'années pour n'importe quel humain de de lire ça c'est en fait la totalité de tout le texte disponible publiquement sur internet alors on se dit c'est une quantité d'information extraordinaire mais en fait on parle au psychologue du développement les successeurs de piag peut-être qui nous disent un enfant de 4 ans a été éveillé un total de 16000 he c'est pas beaucoup de donné 16000 he c'est 30 minutes de d'upload sur Youtube on a 2 millions de de de ner de de de fibres dans d'une air optique 1 million par œil chaque fibre d'une air optique véhicule environ un CT par seconde c'est un peu moins mais peu importe donc le le volume de données qu'un qu'un gamin de de 4 ans à vue et d'environ 10 à la puissance 14 octé à peu près le même ordre de grandeur que le plus grand des LLM et tout ça en 4 ans alors on nous dit oui mais bien sûr le le le contenu visuel est beaucoup plus redondant que le texte oui c'est vrai mais justement il faut de la redondance car les systèmes d'apprentissage se reposent sur la redondance pour apprendre la structure la structure des données la structure du monde s'il y a pas de redondance si on lu si on donne un système d'apprentissage des des aléatoires il n'y a pas de de possibilité d'apprentissage c'est pas possible il y a pas structure dans les données donc il faut que les données soient redondantes pour apprendre et bien sûr la vidéo est plus redondante que le texte mais c'est plutôt un avantage alors à partir de ces observations de 4 ans ou même que de 4 mois un enfant est capable d'apprendre des concepts sur le monde physique assez complexe en quelques mois principalement par observation et un petit peu par interaction dans les dans les qu premers mois de la vie c'est essentiellement par observation et puis ensuite les enfants sont capables d'attraper les objets les manipuler et cetera donc il y a plus d'interaction mais les enfants apprennent le fait qu'il a des objets animés ou inanimés que des objets qui sont posés peuvent être stable ou tomber euh la notion de permanence des objets qui apparaît très très tôt peut-être avant 2 mois le fait que des objets appartiennent à des catégories naturelles ils ont pas besoin de savoir parler pour comprendre une table une chaise sont de choses différents et qu'un chat c'est quelque chose de différent aussi et puis vers 9 mois apparaît la notion physique intuitive la gravité l'inertie des choses comme ça donc qui fait que on a un sens commun on sait comment fonctionne le monde on sait ce qui est possible on sait ce qui est impossible dans une certaine mesure et donc c'est ça prend beaucoup de temps mais c'est appris essentiellement par observation la grosse question pour moi c'est comment faire en sorte que les machines apprennent comment fonctionne le monde de la même manière que les enfants alors il y a une idée très simple qui est l'apprentissage autosupvisé et qui est utilisé pour entraîner les LLM ou peut-être pas les LLM tel que chat GPT mais en tout cas ceux qui qu'on utilise pour faire la traduction par exemple ou pour faire la la détection de discours aux des choses comme ça on prend un texte on on on fait subir une espèce de corruption à ce texte ce qu'on fait très souvent c'est qu'on enlève certains mots on change certains mots et on entraîne gros réseau neuron à prédire les mots qui manquent d'accord et ce faisant le système en fait pour arriver à résoudre cette tâche élabore une espèce de représentation interne de de la langue qui lui permet de de de de contenir le la sémantique la syntaxe la grammaèire enfin tout ce qui est assez extraordinaire alors ça ça marche très bien pour le texte ça marche bien pour les séquences d'ADN ou de protéines enfin de d'acide aminé ça marche bien pour des choses qui sont disons symboliques ou discrètes et bien sûr une idée très naturelle sur laquelle je travaille depuis une bonne quinzaine d'années c'est de faire un peu la même chose avec la vidéo prenons une vidéo faisons subir une espèce de corruption à cette vidéo et ensuite entraînons un grand réseau de neurone à prédire les morceaux qui manquent dans cette vidéo peut-être le futur de cette vidéo par exemple la continuation de cette vidéo et ça ça marche pas mais alors pas du tout ça marche pas parce que le nombre de choses qui peuvent se passer dans dans le futur d'une vidéo est infini de certain manière il y a plein de choses qui peuvent se passer et si on entraîne un système à faire une prédiction ce qu'il prédit c'est la moyenne de tous les futurs qui puissent se passer donc c'est une image toute floue c'est exactement ce qui se passe en haut avec la petite fille euh les les premières euh images de cette courte vidéo sont observées les deux dernières sont prévues sont sont prédites et euh elles sont très floues euh on a travaillé aussi avec des des des vidéos un peu euh symbolisé quoi comme euh la vidéo en dessous qui sont des des des voitures qui qui se promènent pardon euh et la la la deuxième colonne à partir de la gauche vous voyez que les les les voitures sur sur cette autoroute devienent tout flou à mesure qu'on fait la prédiction à cause de ce problème alors on a trouvé des solutions partielles à ce problème avec ce qu'on appelle des modèles à variable attente don je parlais un petit peu précédemment mais en fait ça marche pas très bien la solution à ça c'est une nouvelle architecture qui s'appelle que j'appelle jepa donc ça veut dire joint embeding predictive architecture et voilà à quoi ça ressemble alors vous allez me dire mais c'est quoi la différence avec ce que vous avz montré tout à l'heure la différence c'est que au lieu de prédire tout ce qui pass dans la vidéo au niveau du pixel on va faire en sorte que l'architecture élabore calcule une représentation abstraite de la vidéo aussi bien la vidéo complète que la vidéo corrompue et ensuite prédise la représentation abstraite c'estd ne va pas prédire tous les pixels de la vidéo mais va prédire représentation abstraite de la vidéo qui va on peutesérer contenir l'information utile de la vidéo mais éliminer tous les détails qui ne sont pas prédictibles si on a une vidéo je sais pas qui est la caméra d'une d'une voiture qui conduit sur la route il est important de pouvoir prédire la trajectoire des autres voitures camion piéton et vélo sur la chaussée mais prédire le mouvement des feuilles des arbres qui bordent la route c'est probablement pas très pas très utile ni intéressant et de toute façon c'est imprédictible parce que c'est complètement chaotique donc il faut un système qui est capable d'élaborer une représentation abstraite qui est élimine les informations qu'on ne peut pas prédire et qui permet de faire des prédictions dans cet espace abstrait donc ça s'appelle jepa il y a une série d'articles avec des étudiants et chercheurs qui travaillent avec moi à MTA et à nwayu qu'on essayer de faire fonctionner ce truc voilà alors voilà les deux architectures mises en en contraste l'architecture générative qui reproduit y qui essaie de prédire y et puis l'architecture je pas qui elle prédit une représentation de Y qui ici s'appelle sy d'accord donc on prend x on calcule SX on prend y on calcule Sy et on prédit syy à partir de SX donc le pour moi le futur de l'intelligence artificielle sont des architectures non génératives très souvent aujourd'hui on assimile dans la presse par exemple li moderne à l' générative pour moi le la prochaine génration système di ne sera pas générative alors bon il y a plusieurs parfums de ces de ces jepa don je vais pas je vais pas entrer dans les détails mais la grosse question c'est comment on les entraîne et cette idée de energy bas malance de de modèle à base d'énergie en fait est vraiment ce qui permet de formuler comment entraîner ces systèmes euh donc on donne une série d'exemples X Y qui sont compatibles les uns avec les autres donc x étant un morceau de vidéo y la continuation par exemple et puis on entraî le système à donner une énergie faible lorsque y est bien la continuation de X et puis il faut s'assurer que si y est pas une bon continuation de X ce moment l'énergie plus élevé il y a de méthodes pour ça déjà il y a un phénomène qui peut se passer c'est que cette fonction d'énergie peut subir ce qu'on appelle un collapse bon français c'estàdire en fait donner une énergie zéro ou la même énergie à tout le monde et ça c'est pas un bon modèle ce qu'il faut c'est un modèle qui donne énergie basse pour les choses sur lesquell on entraîne mais énergie plus haute pour les choses surquelles on entraîne pas il y a de deux catégories de méthodes pour ça les méthodes contrastives et les méthodes régularisées les méthodes contrastives consistent à produire des paires X Y qui sont incompatible et de faire monter le l'énergie produite par le système en ajustant ces paramètres et en fait ça c'est pas très efficace dans des espaces de grande dimension le nombre d'endroits il faut pousserénergie vers le haut est trop grand et ça ça passe pas vraiment à l'échelle donc c'est plutôt les les méthodes régularisées qui consistent à dire on va limiter le volume d'espace qui peut prendre une énergie basse c'est-àdire que quand on pousse l'énergie vers le bas d'une région de l'espace le reste doit monter parce que il y a qu'une quantité limitée de de de un volume limité de région qui peut prendre une énergie basse alors ça semble un petit peu mystérieux mais je vais vous donner des exemples donc encore une fois ces deux ces deux méthodes contrastives et régul régularisé je n'aime plus les méthodes contrastives même si contribué à les inventer au début des années 90 je suis devenu beaucoup plus enthousiaste des méthodes régularisées alors pour tester si c'est si ces choseslà marchent bien on on entraî des des réseaux de neurones une des premières expériences qu'on a fait il y plusieurs années c'est entraîner des réseaux de neurones de manière contrastive ou non contrastive on leur donne une paire d'images qui sont en fait différentes versions de C de cette même image et on entraîne un réseau de neurone en fait à produire la même représentation pour ces deux images ou peut-être de prédire la représentation d'une des d'une des images à partir de la représentation de l'autre image donc là on a on a deux images une qui est un peu zoomée l'autre qui est un peu un peu plus angle large et puis on on entraîne le système simultanément à trouver une représentation dans lequelle on peut prédire mais qui conserve le plus d'informations possible sur l'entrée une fois que l'encodeer a été a été entraîné on utilise la représentation construite par encodeur comme entrée d'un classif un classifieur qui lui est entraîné de manière supervisée et on mesure la performance de ce classifieur sur des des base de données d'image standard et ça ça marche très bien les méthodes qui sont basées sur la reconstruction donc des méthodes génératives tel que des autoencodeur autoencodeur de débruitage autoencodeur masqué les les autocordeur variationnel et c tout une série de méthodes pour ça ne marche pas ne marche pas aussi bien euh et donc on a vraiment beaucoup d'indices qui nous montrent que les méthodes génératives appliquées à l'image ne March pas par contre les méthodes à base de joint and beding sont vraiment une bonne solution on on on obtient des résultats qui sont bien meilleurs je vais pas vous ennuyer avec une table de résultats mais euh c'est vraiment très clair alors les méthodes euh contrastives pour ça euh fonctionnent euh elle date des années 900 euh et puis des résultats un peu plus récents euh 2020 simclear mais euh représentation produite par C systèm en fait son un petit peu dégénéré donc on préfère les méthodes régularisé et dans le dans le cadre d'une architecture JEP ce que ça veut dire c'est avoir une espèce de mesure du contenu informationnel de de la sortie de l'encodeur et qui serait qui fer partie du coou minimisé par le par l'apprentissage et donc maximiser le contenu informationnel de la représentation produite par les encodeurs alors il y a un gros problème de avec ça c'est qu'on ne sait pas maximiser un contenu informationnel on sait même pas mesurer le contenu informationnel on peut estimer un petit peu une borne supérieure à un contenu informationnel mais ce qu'on veut c'est maximiser le contenu informationnel donc ce qu' nous faudrait ce serait une bne inférieure comme ça quand on pousse la bne inférieur vers le haut ça pousse aussi le contenu informationnel et malheureusement on n pas de bandes inférieur on a des bandes supérieures donc on pousse vers le haut cette bande supérieure et on croise les doigts ou peut-être on pris si on est religieux pour espérer que le vrai contenu informationnel en fait suive la bande supérieure qu'on qu'on maximise et ça marche alors il une série d'articles d'algorithm qui ont été produit par M collaborateurs et moi un qui s'appelle Barl twins un autre qui s'appelle vireg ça veut dire variance invariance covariance regularization euh et puis une série d'autres articles qui sont des variations de de vicreg et puis d'autres gens qui ont proposer des algorithmes un petit peu similaires un qui s'appelle MCR MCR square de de du laboratoire de Yima à Berkley et puis un autre qui s'appelle mmcr donc très proche comme nom qui elle vient de mes collègues de neurosciences à à NYU S youngen et et reu mon Chali euh euh et euh alors ça ce sont des méthodes par maximisation contenu informationnel et on peut voir indirement que c'est une espèce de régularisation justement du volume d'espace qui peut prendre une énergie basse mais je va pas rentrer dans les détails et puis une autre un autre ensemble de techniques son ce qu'on appelle les méthodes de distillation qui elle alors y une méthode qui a été proposée en 2020 Parè de Deep qui s'appelle byol et puis d'autres méthode proposé par mes collègues de de M simsam Dino et puis une méthode plus récente à laquelle j'ai contribué avec des collègues de Paris et Montréal qui s'appelle PA et puis une version vidéo qui s'appelle vjpa alors ces méthodes là ne sont pas basé sur une maximisation d'information elles sont basé sur une espèce de espèce de comment je dirais système D je sais pas très bien comment exprimer ça en anglais un hack un cl et c'est une idée en fait qui consiste à pour une raison mystérieuse essayer de partager les poids d'une manière un petit peu mystérieuse entre les deux encodeurs donc les deux encodeurs doivent être identiques au niveau architecture et puis doivent partager les poids et puis on doit propager les gradient que d'un côté et puis bon il y a tout un tas de ruses comme ça qu'il faut appliquer mais à la fin le système apprend sans collapse c'està-dire sans le phénomène le pire qui peut arriver où le système ignore les entrées et en fait produit des représentations qui sont constantes et identique et donc le problème de de prédiction est résolu mais le système est pas du tout intéressant donc ça évite le collapse pour tout vous dire je ne comprends pas complètement du point de vue théorique pourquoi mais certains de mes collègu aussi de MTA Yang Tian et ses collaborateurs si gangouli et et Shida on on fait un article théorique qui montre que finalement non c'est il y a une bonne raison pour laquelle ça marche et [Musique] cetera je comprends pas tout mais ça marche alors il a une méthode de distillation qui est un petit peu améliorée qui s'appelle Dino V2 et celle-là on comprend pourquoi elle ne collapse pas parce qu'elle est un petit peu plus explicite et c'est un c'est un modèle open source qui qui est entraîné de manière complètement autosupvisée que vous pouvez télécharger à l'URL montrer ici et qui est un espèce de d'extracteur de représentation d'image générique qui qui est utilisé de par le monde par beaucoup de gens pour en fait faire de compréhension analyse image ce qu'ils font c'est qu' extrait les les caractéristiques produites par Dino 2 et puis il les il branche un autre système par-dessus qui est entraîné de manière supervisée mais qui a besoin de très peu de données parce qu'il est tout petit pour résoudre un problème de je sais pas segmentation d'image biologique trouver les cellules et les les noyaux des cellules ou essayer d'identifier certaines plantes à partir de de d'images satellite et cetera alors ça marche très bien je vais pas vous ennuier avec les détails VO une application assez assez amusante faite par Camille coupri avec des ses collaboratoires à méta à Paris qui consiste à estimer la hauteur de la de la canopée à partir de très peu d'images euh donc on a beaucoup d'images satellite bien sûr de la terre entière on a très peu d'images étiquetées dans lequel on connaît la hauteur de la canopée pour ça il faut des avion équipé de lidar ou des drones équipés de lidar pour estimer la hauteur donc là on n pas énormément de données mais on là on a des données de ce type là relativement diverses donc ce que ce qu'a fait Camille c'est utiliser ces utiliser les les les représentations d'inov2 entraîner une une tête au-dessus d'inov2 manière supervisée avec le peu de données qu'on a venant de de litar et puis ensuite appliquer ça au monde entier et on peut estimer la hauteur de la canopée partout dans le monde et donc en déduire la quantité de carbone emprisonné dans la végétation et c'est une quantité très intéressante pour la la prédiction du du changement climatique VO une application de l'IA qui est positif en changement climatique et non pas négatif alors une version de de de jepa c'est image jepa c'est aussi une méthode par distillation et qui marche extrêmement bien et qui est très rapide à entraîner et qui qui n'a pas besoin de faire de ce qu'on appelle l'augmentation de données autre que du masquage je vais pas vous ennuyer avec les détails de comment ça marche mais en gros on prend une image on la masque partiellement et puis ensuite on entraîne une architecture jepa à prédire la représentation de l'image complète à partir de l'image partiellement masquée ça marche extrêmement bien c'est pas encore complètement utilisable comme extraction caractéristique générique comme dinov V2 mais mais c'est Open Source vous pouvez télécharger le modèle de même que pour dinov V2 et puis et puis on a fait une version de ça pour la vidéo dans lequel on prend une vidéo on fait un masquage partiel et puis on entraîne le système et puis à la fin on branche une une tête sur la représentation extraite du système pour classifier par exemple l'action qui se produit dans une vidéo on obtient d'excellents résultats avec ça qui à partir de méthode autosupervisé qui marche bien bien mieux que les méthodes qui ont été entraînées à reconstruire la vidéo telle que je vous disais précédemment donc on a beaucoup d'indices maintenant qui nous montre que les méthodes par reconstruction les méthodes génératives ne marchent pas elle ne marchent pas pour le MIAGE elle ne marche pas pour la vidéo enfin elle marche mais pas bien les seules méthodes qui marchent sont ces méthodes à joint and bedding donc enchassement en joint et en particulier les jepa euh donc en français architecture prédictive à enchassement joint l'acronyme est pas aussi ne glisse pas sur la langue euh encore une fois je vais pas vous embêter avec avec tous les détails mais ça marche vraiment très bien cette histoire de vjepa et en fait on a des des des débuts de de résultats qui sont on va soumettre un article très prochainement qui montre que ce ce système vgpa bien qu'il sonit entraîné que sur des vidéos très courtes de 16 tram en fait est capable d'un certain sens commun c'està-dire que si on lui donne des vidéos possibles donc par exemple une vidéo dans lequel il y a une balle qui roule et qui passe derrière un écran et puis ensuite on baisse l'écran et la balle est là et puis on montre une autre vidéo qui est quasiment identique avec une balle qui roule qui s'arrête derrière un écran on baisse et la boule est plus là c'est pas une vidéo possible il a un objet qui a disparu une espè de discontinuité donc si on monte des paires de vidéo à ce système on lui demande de nous de nous dire quelle est l'erreur de prédiction de de cette vidéo qu'il est capable de prédire ce qui va se passer dans la vidéo systématiquement il nous dit que la vidéo impossible a une erreur de prédiction plus élevée que la vidéo possible ce système a un petit peu appris ce qui est possible et ce qui est impossible dans la réalité c'est un bon début donc on écrit finit un article là-dessus et puis un peu plus intéressant et c'est là-dessus que j'ai terminé un modèle récent qui s'appelle Dino World model alors j'en ai pas encore parlé c'est pas publié et c'est la première fois que j'en parle donc vous avez la primur c'est un un article qui n'est pas encore disponible sur archive mais qui sera probablement d'ici une semaine par une de une étudiante s'appelle Gou jou qui qui est cupervisé par lerel Pinto un collègue de NYU en robotique et moi-même et alors ce qu'a fait g c'est entraîner un modèle du monde un prédicteur qui est conditionné sur des actions pour faire la planification mais sans entraîner l'encodeur l'encodeur est pré-entraîné et ce sont en fait des représentations d'images basé sur Dino V2 ok donc histoire c'est ça on prend on prend une image on l'a fait passer par l'encodeur d'inov 2 qui nous donne une représentation de de cette image euh et puis bien sûr on observe une une séquence d'imag qui correspond à une séquence d'action qui est prise dans dans le monde qui est en l'occurrence simulé hein c'est un environnement robotique simulé et on entraîne un prédicteur à prédire quelle va être la représentation de l'état du monde à un santé + 1 en fonction de la représentation du à l'instant T et de l'action qui a été prise à l'instant T d'accord à partir de ce modèle on peut planifier une séquence c'estàd on peut on peut on peut dire démarrons d'une situation particulière calculons la représentation ensuite appliquons notre modèle du monde avec une séquence d'action dont on fait l'hypothèse puis ensuite on peut mesurer une fonction de coût qui mesure la distance entre l'état final et un état cible qu'on a et l'ét cible on calcule simplement en mettant une image de l'ét cible et en faisant passer par l'encodeur Dino simplement une distance clilienne dans l'espace de représentation et ensuite par optimisation donc on essaie de trouver une séquence d'action qui minimise ce coût alors cette technique de d'optimisation j'aurais dû vous le dire plus tôt c'était sur le sur le transparent c'est ce qu'on appelle en en théorie de la commande optimale MPC model predictive control c'est complètement classique ça date du début des années 60 mais classiquement on fait ça avec un modèle du système qu'on contrôle qui est écrit à la main là ce dont je parle c'est un modèle qui est appris entièrement à partir de données donc c'est ça qui en fait un petit peu la différence et appris non seulement appris mais compliqué c'est un gros rseau neurone qu'on entraîne à prédire l'état du monde futur à partir de l'état du monde actuel et de l'action et ça marche bien dans des cas un petit peu disons décle tiens je sais pas pourquoi ça montre ça comme ça je sais pas pourquoi c'est un peu superposé mais donc la tâche ici j'espère que je va pouvoir répéter le alors la tâche ici ce que vous voyez on voit pas malheureusement l'exemple en bas à gauche mais c'est une t'ppelle P qui consiste à pousser un espèce de truc en forme de T avec un petit point de le bouger et de de le pousser de manière à ce qu'il arrive à une une position cible déterminée à l'avance et ce que vous voyez là c'est c'est ça c'est-à-dire alors voilà un autre exemple deux autres exemples un dans lequel le but est de planifier la trajectoire d'un d'un petit point rouge d'un côté d'un mur à un autre en passant par la porte et le système a dû apprendre que il peut pas traverser les murs et qu'il est obligé de passer par la porte il arrive à planifier une trajectoire alors c'est un problème qu'on peut résoudre à la main bien sûr c'est complètement trivial mais c'est intéressant de voir que le système est capable de la de résoudre et puis l'autre est un petit peu moins le le deuxième est un petit peu moins trivial il consiste à planifier une séquence d'action d'un d'un brin de robot pour déformer une une espèce de corde pour qu'elle recouvre une euh pour qu'elle ait une forme et une position particulière alors bon on a produit des des ensembles des exemples d'apprentissage dans toutes ces ces ces tâches euh je on a comparé ça à d'autres méthodes qui ont pas l'air de marcher particulièrement bien donc une méthode en part en particulier qui s'appelle Dreamer V3 qui est été produit par danisar Hafner et ses collaborateurs à à Deep mind mais qui n'est qui n'est pas qui n pas capable de de de marcher aussi bien les images qui sont montrées ici sont des des images qui sont produites à partir de la représentation interne prédite par le système et passer par un décodeur qui est entraîné séparément donc on a un décodeur qui produit l'image mais ce décodur n'est pas utilisé pour entraîner le système c'est juste une technique de visualisation alors bon ces problèmes là sont un peu simplistes et pas trop pas trop intéressant il y a un problème un petit peu plus intéressant qui s'appelle qui s'appelle granular et j'espère que j'ai gardé la vidéo dans le speech pour la montrer mais c'est vraiment amusant donc là le le le le but de cette de ce de ce cette tâche c'est on a une espèce de de grain bleu sur une table en position aléatoire et une action consiste à baisser un bras de robot le bouger d'unun Delta x Delta y et le monter c'est une action d'accord donc quatre chiffres quatre nombres coordonné où on baisse le le bras et puis Delta x Delta y et onlève le bras et la tâche est de faire en sorte de regrouper ces ces ces grains ces grains bleus dans un carré ou dans une autre forme à partir d'une forme aléatoire alors on a essayé plusieurs méthodes et notre méthode a l'air de marcher beaucoup mieux que que que les autres on a ça de manière un petit peu quantitative pour une série de de de d'environnement ici donc donc pas seulement granular qui est le le le truc à à droite où là la la mesure de performance est une ce qu'on [Musique] appelle la mesure de comment dit champfer en français je me rappelle même plus et et donc dans lequel des valeurs plus basses sont meilleures donc notre méthode Dino Dino World model est en bleu donc fonctionne bien mieux que Dreamer ver 3 tdmpc2 qui sont d'autres d'autres méthodes plus d'apen pas renforcement en fait mais avec des des World mod aussi et puis pour les autres tâches mais je vais pas rentrer dans les détails alors voilà quelques vidéos qui montrre le fonctionnement de de P et de de point et puis finalement donc ce que vous voyez à droite ici c'est les étape successive après chaque action je vais vous moner ça encore après chaque action euh le le le la configuration des des des des des petits granules euh et ce qui est en haut euh c'est ce qui se passe effectivement quand on prend ces actions c'est des actions qui ont été planifié à l'avance et qui sont exécuté en boucle ouverte c'està-dire on regarde pas le résultat des actions on exécute les ces cinq actions en l'occurrence si si je me rappelle bien et en haut est représenté le résult de ces 5 actions dans le simulateur réel et en bas c'est la prédiction produite par le modèle interne du système et donc est assez précise en fait là c'est une prédiction qui montre que D3 par rapport à Dino marche pas très bien voilà donc on a des premiers résultats qui montre que c'est histoire de planification inférence par optimisation avec des World model qui comprennent un petit peu une dynamique compliquée dans le qu il y a des interactions entre des grains du la friction et cetera une dynamique vraiment compliquée euh on arrive à le faire donc y compris pour des systèmes physiques qu'on aurait du mal à modéliser à la main voilà donc j'ai un certain nombre de recommandations abandonner les modèles génératifs au profit des japa abandonner les modèles probabilistes au profit des modèles à base d'énergie abandonner les méthodes contrastive au profit des méthodes régularisées abandonner l'apprentissage par renforcement mais ça je dis depuis des années ces quatre choses sont les quatre choses les plus populaires aujourd'hui dans le domaine du machine learning donc ça me rend moi impopulaire mais bon je suis habitué alors il y a encore plein pas mal de de problèmes à résoudre là-dedans arriver à faire marcher ces ces ces système à l'échelle quoi avec beaucoup de données les faire marcher non seulement sur la vidéo mais aussi bon des vidéos réelles sur du texte sur la parole sur du code pour la génération de code et la planification pour les dialogues pour les maths pour tout un chos intéressante des algorithmes d'optimisation pour la planification parce que en fait c'est pas facile de d'optimiser une séquence d'action pour minimiser un coup quand on passe à travers des gros neurones des tas de problèmes de non convexité et cetera des JEP avec variant avec variable attente qui nous permet de gérer les inser certitude et puis de planifier en présence d'un certitude ce qui est un petit peu compliqué et bien et bien sûr de faire la la planification hiérarchique ce sont les problèmes pas résolus si vous commencez un doctorat maintenant essayz de travailler sur ces problèmes là c'est vraiment intéressant et puis euh vous aurez pas trop de concurrents et puis d'autres problèmes dont je vais pas entrer dans les détails alors voilà le futur c'est des systèmes d'IA un petit peu universels des assistants qui peut-être auront le niveau d'intelligence humain d'ici 7 8 10 ans peut-être 20 on sait pas mais on espère que ces avancées en fait conduiront vraiment à des des nouveaux un nouveau type de de système intelligent dans les années qui viennent des systèmes d'IA vont constituer un espèce de dépositaire de toute la connaissance humaine c'est-à-dire quand on aura besoin d'accéder à la connaissance au lieu d'aller dans une bibliothèque ou d'aller faire une recherche sur internet en fait on demandera simplement à notre assistant alors ça ça va ça ça compte ça conduit à un monde dans lequel la majorité de nos interactions avec le monde numérique se feront par l'intermédiaire d'assistant Dia et il n'est pas possible d'imaginer que ces systèmes d' vont être contrôlés par une poignée de d'entreprises de de tech sur la côte ouest des États-Unis ce serait complètement inacceptable pour le gouvernement suisse et certainement gouvernement français et pas mal de gouvernements à l'extérieur des États-Unis que le la la totalité de l'information numérique qui parvient à leur citoyens et contrôlé par de ou tro entreprises en Californie ou sur la côte ouest c'est c'est un danger pour la démocratie même si ces entreprises sont très bien intentionnées donc ce qu'il faut ce sont des plateformes open source c'est une des raisons pour laquelle j'ai été un grand avocat ou défenseur des promoteurs des plateformes Open Source di c'est pour pouvoir permettre la diversité euh linguistique culturel les systèmes de valeur des systèmes d'IA dans le futur si on veut vraiment que des des LLM dans dans un premier cas et puis des systèmes di plus perfectionnés par la suite en fait euh soit vraiment le dépositaire de toute la connaissance humaine il va falloir que l'entraînement de ces modèles soit distribués dans le monde pour que euh les modèles entraînés en Suisse comprennent le français bon ça va pasêtre trop compliqué il juste besoin de corriger les enfin de comprendre que 8 ans et 90 c'est pas 80 et 90 donc bon par rapport au au parisiens bon c'est pas trop compliqué euh mais il faut aussi qu'ils apprennent le revanche le le le suisse allemand qui n'est pas écrit donc il y a très peu de matériaux en fait pour entraîner ces systèmes et puis tous les dialectes qui sont parlés en Europe les les les 2000 langues qui sont parlées en Afrique les les les 1500 ou dans ces eaul qui sont parlés en Inde il y a déjà 22 langues officielles en Inde les 700 qui sont parlé en Indonésie et puis toutes les langues qui sont qui sont pas écrites a plus en fait de par le monde que de langues qui sont écrites alors pour ça il va falloir que l'apprentissage de ces systèmes soit distribué de par le monde de manière à ce que en Inde on puisse 'entraîner sur les langues indiennes mais à la fin qu'on a système qui soit un petit peu commun c'estàd qu'il a l'intelligence un peu commune du monde entier donc ça l'open source est nécessaire à ce futur et et puis il va falloir travailler sur ces histoires de de de de de garde fou et cetera alors le problème de l'Open Source c'est que il y a des gens qui pense que les systèmes d'IA sont intrinsquement dangereux et donc il faut réglementer la recherche et le développement en IA et réglementer la distribution de système d'IA particulièrement système open source et ça ça tue l'OP source ça ne vaut pas le coup pour une entreprise comme mat par exemple de distribuer un modèle en open source il y a le moindre risque une réglementation nous disent c'est trop dangereux donc ça risque la régulation particulièrement en Europe risque de de tuer l'OP source alors les gouvernements européens non pas le gouvernement de l'Europe mais les gouvernements EUR euréens sont très conscients de que le le chemin vers la la souveraineté de l'IA en Europe passe par l' Open Source et donc sont en train de se battre avec avec l'Union européenne c'est un petit peu cfcayen je vais arrêter là merci beaucoup [Applaudissements] je crois qu'il y a des des micro circulant je tiens pardon je tiens à remercier pour cette présentation hyper intéressant et visionnaire et on a un petit peu de temps pour des questions n'hésitez pas poser profiter de cette occasion merci pour la présentation vous avez parlé de plateforme juste maintenant qu'est-ce que vous envisagez pour la question des infrastructures quelque chose de très commoditisé ou beaucoup plus décentralisé qu'aujourd'hui justement les modèles les infrastructures de calcul j'imagine c'est ça vous parler oui alors évidemment pour entraîner ou même simplement pour affiner un modèle de grande taille il faut descendes de calcul assez important typiquement l'espèce de de de quantité un peu irréductible qu'on utilise à méta c'est un un cluster de 16000 GPU alors le problème de ça c'est qu'un cluster de 16000 GPU déjà ça coûte 1 milliard de euros franc suisse ou dollars c'est la première chose et ça consomme beaucoup d'énergie de l'ordre du gigw donc il faut se placer il faut placer ces centres de de calcul dans des pays où il y a de l'énergie non seulement à bas prix mais aussi décarboné et ça ça veut dire la France parce qu'il y a l'énergie nucléaire la Suisse parce qu'il y a l'hydroélectricité le Québec parce qu'il y a l'hydroélectricité ou le Costa Rica parce queélectricité mais bon il y a d'autres problèmes et puis bon quelques autres naturellement mais on peut pas on peut pas utiliser par exemple énergie solaire ou ou éolienne pure parce que il faut bien faire tourner les les machines quand il y a pas de soleil ou pas de vent et et on sait pas stocker l'énergie à l'échelle qui est qui est requise à l'heure actuelle donc beaucoup de gens parlent en fait qui sont qui s'intéressent à au futur de de l'IA parlent en fait d'installer des des centres de calcul à côté de central nucléaire tout simplement ça évite de perdre l'énergie dans les trans trans dans dans le transport de l'énergie merci pour la présentation j'ai une question un tout petit technique pensez-vous que de théorie de information peut euh un peut aider nous de créer un nouvelle forme de entraînement des modèles maintenant parce que vous avez mentionné des théoriesinformation comme mation une chose comme ça est-ce que vous pensez que c'est possible oui alors c'est très possible alors la théorie de l'information ne malheureusement ne nous dit pas comment mesurer l'information ça n dit simplement les propriétés de si on pouvait mesurer la quantité d'information voilà les propriétés qu'elle aurait euh mais ne nous ne nous dit pas comment les mesurer parce que pour pouvoir mesurer le contenu informationnel il faut pouvoir estimer des distributions probl ité et on sait pas estimer des distributions de probabilité de manière absolue il nous faut soit énormément de données soit des des distributions à priori pour régulariser le l'estimation et c'est complètement arbitraire donc en fait on n pas de de moyen de faire ça on a pas de moyen d'estimer des des dépendances par exemple de manière fiable surtout en ha dimension donc donc ça nous ça permet résoudre un certain nombre de problèmes c'est-à-dire dérivver des propriétés un peu un peu générales mais pas vraiment en pratique de de réduire ça à un algorithme un algorithme pratique ceci dit euh j'ai un un postdoc brillant qui travaille avec moi qui s'appelle Ravid Schwartz Ziv qui est un expert en théorie de l'information et qui a écrit une série d'articles là-dessus sur la l'applicabilité de la théorie deinformation sur l'entraînement SSL par maximisation d'information et autres merci beaucoup pour la présentation c'était vraiment enrichissant et je voulais demander les les systèm basé dans j'ai bien compris bien pour ce qui conc les images et les vidé est-ceence bienéri ai pour ce qui concerne les tes lié au langage et et comment vous vous vous expliquez le fait que des modèles aussi simples probabilistes et génératif puir ces capacités émergents qui semble risonner même si il R vraiment pas selon votre définition j'imagine donc là la réponse à la première question c'est on sait pas encore euh mais on a au moins deux projets là-dessus donc utiliser des JPA sur le texte et puis un autre qui est utiliser des JPA pour pour le le code donc la l'écriture de code et l'écriture de code évidemment on peut écrire du code de manière complètement automatique donc on entraîne un LLM et puis on fait un petit peu de de F tuning mais à la fin quand on écrit un programme compliqué ou un système logiciel on est obligé de planifier un peu y compris de manière hiérarchique avec structure de données et cetera par que les systèm actuel généraation code ne savent pas faire donc on travaille làdessus je peux pas vous donner résultat encore ah oui puis une deuxème question sur pourquoi les pourquoi les oui voilà donc les les performances des des modèles sont enfin qu'on appelle decodeer only enfin des purement décodeer donc architecture la GPT pourquoi marche-il si bien quand il les entraînent sur beaucoup de données oui c'est assez bluffant bien sûr mais c'est essentiellement la régorgitation c'estàdire que un des meilleurs exemples de ça si on demande LLM quel qu'il soit de de donner la solution du du du du petit puzzle qu'on donne aux enfant on a un loup une chèvre et un chou d'un côté d'une rivière on a un bateau qui peut orter que deux objets à la fois et puis bien sûr le loup veut manger le la chèvre et la chèvre veut manger le chou comment on fait alors on transporte d'abord la chèvre le loup va pas manger le chou ensuite on transporte le chou mais on est obligé de ramener la chèvre sinon elle va manger le chou et puis ensuite on on emmène le loup et puis à la fin on emmène la chèvre puis là bon comme tout le monde est surveillé il y a pas de problème on pose ce problème là GPT whatever ça marche très bien bien sûr mais c'est pas parce que la solution de ce problème apparaît partout sur internet donc le système a juste appris par cœur en gros ensuite on change les données du problème un petit peu on lui dit non il a il y a juste un loup et un chou il nous donne la même solution o il faut faire trois allers-retours sans comprendre en fait sans avoir ce ce modèle mental du monde que quand on part d'un côté à l'autre on est plus du premier côté on est que dans le deuxème un objet peut pas être à deux endroits en même temps et que les loups m mangent pas les choux et cetera enfin bon toutes ces toutes ces connaissances en fait ne sont pas présentes dans ces dans ces LLM alors bien sûr depuis que ce genre de critique a été émise les gens qui construisaient les LLM ont mis toutes les variations possibles de ce problème là et ont entraîné le système répond correctement en fait il y a une histoire de ce typ là il y a quelques années où on m'avait posé c'est un philosophe collègue de NYU qui m'avait posé la question y y a-t-il un problème que que les llèves ne peuvent pas résoudre al j'avais dit ouais c'est très simple donc c'était il y a quelques années déjà j' dit imaginez 7 engrenages qui sont tous placés sur des axes et chaque engrenage est engrainé avec celui d'avant et CELI d'après maintenant on tourne l'engrenage numéro 2 dans le sens des aigu d'une montre comment va tourner l'engrenage numéro 7 alors là non pas répondre que c'est trop compliqué il faut faire une séquence de de raisonnement don ils sont pas capabl et puis avoir modèle mental et alors quelques mois plus tard et bon et puis ça cette discussion ét ouverte sur Twitter quelques mois plus tard quelqu'un me dit en fait le problème est facilement résolu maintenant par les parler en fait parce que av été entraîné avec réentraîné avec Twitter don le problème bien sûr la solution était là tout le monde en avait parlé et cetera et donc le même philosophe imagine un autre problème que que les l actuel pe pas résoudre très simple tu prends engrenage et tu les mets sur un cercle d'cord il sont tous engin les un avec les autres avec de voisins maintenant ESS tourner l'engrenage numéro 2 dans le sens montre comment va tourner l'engrenage numéro 7 et là le système fait comme si ils étaient sur une ligne et bien sûr c'est pas possible c'est un piège quand on quand on a un nombre impaire d'engrenage et qu'on essaie d'en tourner un ça tourne pas c'est pas possible ils sont coincés et bien sûr le LM n'a aucune idée donc bon évidemment il y a plein d'humains qui peuvent pas non plus résoudre ce problème intuitivement mais disons réfléch suffisamment peuvent le peuent le résoudre ENIT y a plein de problèmes comme ça qui nécessit une espèce d'image d'image mentale de modèle mental dont les sont incapables sauf s'ils ont été directement entraînés avec la réponse merci beaucoup malheureusement il faut finir et j'aerais encore [Applaudissements] remercier pour les avec modèle 2 3 merci beaucoup 2 on ok merci beaucoup merci [Applaudissements]"
}